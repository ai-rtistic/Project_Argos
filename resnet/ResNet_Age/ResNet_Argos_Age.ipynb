{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2ZFevbP9wTn"
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iB_5kSEJ9vAr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9n_NWk2H9zUZ",
    "outputId": "8724433c-b7cf-4839-a659-f0a6555f4d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnvreZa_94ie"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dSG3ohC9X0Ja"
   },
   "outputs": [],
   "source": [
    "#배치 사이즈 및, 에폭 설정\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04frCOVkX2jH",
    "outputId": "b76f4862-dc2a-4d27-bf45-974e80cdcc82"
   },
   "outputs": [],
   "source": [
    "#데이터를 dataloader에 담아주는 과정\n",
    "transform_base = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()]) \n",
    "\n",
    "train_dataset = ImageFolder(root='datasets/market1501/train', transform=transform_base) \n",
    "val_dataset = ImageFolder(root='datasets/market1501/val', transform=transform_base)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kO5ubR6AyU3"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgeB1Yy6y7iF",
    "outputId": "73b06a43-ee05-4c9b-b4c7-74068c89b388",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       BottleNeck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 23,516,228\n",
      "Trainable params: 23,516,228\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.71\n",
      "Estimated Total Size (MB): 376.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4 #블록의 마지막 레이어에서 출력 차원을 4배로 늘린다\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #Resnet50은 1x1, 3x3, 1x1을 거치는 3개의 컨볼루션 레이어가 하나의 블록으로 구성된다.\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential() #x를 그대로 사용\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        #stride가 2 이상이어서 feature map의 크기가 다르거나, 출력층의 채널수가 다른 경우 1x1컨볼루션을 이용해 x의 크기를 맞춰준다.\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=4, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        #7x7의 컨볼루션 레이어와 맥스풀링\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        #3개의 블록이 있으며 3x3 컨볼루션 레이어에서도 stride를 1로 두어 output size에 변화가 없다.\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        #conv3~5에서는 각각 4,6,3개의 블록이 있으며 3x3 컨볼루션 레이어에서 stride를 2로 두어 output size가 절반으로 줄어든다.\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        #Average Pooling을 통해 각 채널에서의 평균값 추출\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        #마지막 출력층의 채널 수인 512*4개가 input으로 들어가 클래수의 수만큼 출력한다.\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        #가중치 초기화\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "# print model summary\n",
    "model_base = resnet50().to(DEVICE)\n",
    "summary(model_base, (3, 224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlp7_e-7UjjS",
    "outputId": "a0471bba-ebac-4731-c858-1afde4b4400d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 4])\n"
     ]
    }
   ],
   "source": [
    "#출력 사이즈 확인\n",
    "x = torch.randn(50, 3, 224, 224).to(DEVICE)\n",
    "output = model_base(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rslSSCoAA5Ug"
   },
   "outputs": [],
   "source": [
    "# Optimizer, Loss function\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "th-2zcPLA5WO"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()  # 모델 train 상태로\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)   # data, target 값 DEVICE에 할당\n",
    "        optimizer.zero_grad()                               # optimizer gradient 값 초기화\n",
    "        output = model(data)                                # 할당된 데이터로 output 계산\n",
    "        loss = criterion(output, target)                    # Cross Entropy Loss 사용해 loss 계산\n",
    "        loss.backward()                                     # 계산된 loss back propagation\n",
    "        optimizer.step()                                    # parameter update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UebmmqfmA5YL"
   },
   "outputs": [],
   "source": [
    "#evaluate\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()      # 모델 평가 상태로\n",
    "    test_loss = 0     # test_loss 초기화\n",
    "    correct = 0       # 맞게 예측한 개수. 0 값으로 초기화\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)     # data, target DEVICE에 할당\n",
    "            output = model(data)                                  # output 계산\n",
    "            test_loss += criterion(output, target).item()         # loss 계산(총 loss 에 더해주기)\n",
    "            pred = output.max(1, keepdim=True)[1]                 # 계산된 벡터값 중 가장 큰 값 가지는 class 예측\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # 맞게 예측한 값 세기\n",
    "   \n",
    "    test_loss /= len(test_loader.dataset)                         # 평균 loss\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)     # test(validation) 데이터 정확도\n",
    "    return test_loss, test_accuracy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo6NZqLmBGQl"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAqivTJNBHOC",
    "outputId": "89b7f1a5-8181-417b-8d17-6c7be37fb2b3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train Loss: 0.0216, Accuracy: 60.56%\n",
      "val Loss: 0.0518, Accuracy: 31.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 2 ----------------\n",
      "train Loss: 0.0146, Accuracy: 67.20%\n",
      "val Loss: 0.0288, Accuracy: 41.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 3 ----------------\n",
      "train Loss: 0.0129, Accuracy: 67.10%\n",
      "val Loss: 0.0243, Accuracy: 50.00%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 4 ----------------\n",
      "train Loss: 0.0117, Accuracy: 69.69%\n",
      "val Loss: 0.0261, Accuracy: 53.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 5 ----------------\n",
      "train Loss: 0.0110, Accuracy: 70.63%\n",
      "val Loss: 0.0281, Accuracy: 52.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 6 ----------------\n",
      "train Loss: 0.0112, Accuracy: 71.18%\n",
      "val Loss: 0.0327, Accuracy: 46.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 7 ----------------\n",
      "train Loss: 0.0107, Accuracy: 71.00%\n",
      "val Loss: 0.0173, Accuracy: 61.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 8 ----------------\n",
      "train Loss: 0.0089, Accuracy: 77.06%\n",
      "val Loss: 0.0177, Accuracy: 61.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 9 ----------------\n",
      "train Loss: 0.0136, Accuracy: 61.10%\n",
      "val Loss: 0.0236, Accuracy: 70.00%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 10 ----------------\n",
      "train Loss: 0.0076, Accuracy: 80.47%\n",
      "val Loss: 0.0184, Accuracy: 62.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 11 ----------------\n",
      "train Loss: 0.0085, Accuracy: 78.53%\n",
      "val Loss: 0.0217, Accuracy: 68.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 12 ----------------\n",
      "train Loss: 0.0111, Accuracy: 76.22%\n",
      "val Loss: 0.0397, Accuracy: 52.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 13 ----------------\n",
      "train Loss: 0.0071, Accuracy: 82.11%\n",
      "val Loss: 0.0346, Accuracy: 61.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 14 ----------------\n",
      "train Loss: 0.0058, Accuracy: 85.52%\n",
      "val Loss: 0.0158, Accuracy: 71.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 15 ----------------\n",
      "train Loss: 0.0044, Accuracy: 89.32%\n",
      "val Loss: 0.0191, Accuracy: 72.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 16 ----------------\n",
      "train Loss: 0.0067, Accuracy: 90.22%\n",
      "val Loss: 0.0201, Accuracy: 71.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 17 ----------------\n",
      "train Loss: 0.0046, Accuracy: 89.27%\n",
      "val Loss: 0.0359, Accuracy: 57.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 18 ----------------\n",
      "train Loss: 0.0022, Accuracy: 95.13%\n",
      "val Loss: 0.0203, Accuracy: 75.00%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 19 ----------------\n",
      "train Loss: 0.0017, Accuracy: 96.07%\n",
      "val Loss: 0.0274, Accuracy: 73.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 20 ----------------\n",
      "train Loss: 0.0017, Accuracy: 96.09%\n",
      "val Loss: 0.0261, Accuracy: 76.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 21 ----------------\n",
      "train Loss: 0.0033, Accuracy: 91.95%\n",
      "val Loss: 0.0230, Accuracy: 71.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 22 ----------------\n",
      "train Loss: 0.0023, Accuracy: 94.61%\n",
      "val Loss: 0.0251, Accuracy: 73.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 23 ----------------\n",
      "train Loss: 0.0019, Accuracy: 95.53%\n",
      "val Loss: 0.0295, Accuracy: 72.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 24 ----------------\n",
      "train Loss: 0.0082, Accuracy: 85.61%\n",
      "val Loss: 0.0357, Accuracy: 73.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 25 ----------------\n",
      "train Loss: 0.0013, Accuracy: 96.97%\n",
      "val Loss: 0.0197, Accuracy: 73.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 26 ----------------\n",
      "train Loss: 0.0015, Accuracy: 96.90%\n",
      "val Loss: 0.0507, Accuracy: 72.50%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 27 ----------------\n",
      "train Loss: 0.0035, Accuracy: 92.79%\n",
      "val Loss: 0.0507, Accuracy: 56.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 28 ----------------\n",
      "train Loss: 0.0023, Accuracy: 95.16%\n",
      "val Loss: 0.0354, Accuracy: 73.75%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 29 ----------------\n",
      "train Loss: 0.0008, Accuracy: 98.17%\n",
      "val Loss: 0.0224, Accuracy: 76.25%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 30 ----------------\n",
      "train Loss: 0.0020, Accuracy: 95.75%\n",
      "val Loss: 0.0547, Accuracy: 66.25%\n",
      "Completed in 0m 58s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    " \n",
    "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
    "    best_acc = 0.0  # best accuracy 초기화\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    " \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()                                     # 학습 시간 계산\n",
    "        train(model, train_loader, optimizer)                   # train 데이터로 학습\n",
    "        train_loss, train_acc = evaluate(model, train_loader)   # train_loss, train_acc 계산\n",
    "        val_loss, val_acc = evaluate(model, val_loader)         # valid_loss, valid_acc 계산\n",
    "        \n",
    "        if val_acc>best_acc:  # update best accuracy\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since # 학습 시간 출력\n",
    "        print('-------------- epoch {} ----------------'.format(epoch))\n",
    "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
    "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
    "\n",
    "    model.load_state_dict(best_model_wts)  \n",
    "    return model\n",
    "\n",
    "base = train_baseline(model_base ,train_loader, val_loader, optimizer)  \t# 모델 학습시키기\n",
    "torch.save(base,'model/resnet.pt')      # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uqz-hy30BLuT",
    "outputId": "afbd5cde-3079-40e9-c595-fc8bf95cac4c"
   },
   "outputs": [],
   "source": [
    "# test data\n",
    "transform_base = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()]) \n",
    "test_base = ImageFolder(root='datasets/market1501/test',transform=transform_base)  \n",
    "test_loader_base = torch.utils.data.DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8fTkqzKdpn8z"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval() #eval 모드\n",
    "    result = None #모델을 거친 확률값(7개 클래스에 대한 softmax)\n",
    "    targets = None #실제 target\n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:  \n",
    "            data = data.to(DEVICE)\n",
    "            #비어있을 경우 그대로 넣어주고\n",
    "            if result is None:\n",
    "              result = model(data).cpu().numpy()\n",
    "              targets = target.cpu().numpy()\n",
    "            #이미 값이 있을 경우 concat을 통해 추가해준다\n",
    "            else:\n",
    "              result = np.concatenate((result, model(data).cpu().numpy()))\n",
    "              targets = np.concatenate((targets, target))\n",
    "    return result, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfaqGgQb1ZuI"
   },
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxZiw7hytuZe",
    "outputId": "2a1c7cfe-e348-4bdd-ffd9-7b2f4f5c5e43"
   },
   "outputs": [],
   "source": [
    "y_pred_base, y_true_base = predict(base, test_loader_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fskesmCAz32A",
    "outputId": "97a27d94-363e-4ba1-cb82-703997089b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base모델 정확도: 0.713\n",
      "base모델 오차 행렬:\n",
      " [[ 8  1  0  0]\n",
      " [12 17  6  1]\n",
      " [ 0  1 14  1]\n",
      " [ 0  1  0 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "print(\"base모델 정확도: {:.3f}\".format(accuracy_score(y_pred_base.argmax(axis=1), y_true_base))) #y_pred_base는 확률값이므로 argmax를 통해 예측 클래스를 뽑는다\n",
    "print(\"base모델 오차 행렬:\\n\", confusion_matrix(y_pred_base.argmax(axis=1), y_true_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoxCF2940l9o",
    "outputId": "35606e45-bf24-4431-d841-e8c00dba42eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.89      0.55         9\n",
      "           1       0.85      0.47      0.61        36\n",
      "           2       0.70      0.88      0.78        16\n",
      "           3       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.71      0.80      0.71        80\n",
      "weighted avg       0.78      0.71      0.71        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_pred_base.argmax(axis=1), y_true_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_AIFFEL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
