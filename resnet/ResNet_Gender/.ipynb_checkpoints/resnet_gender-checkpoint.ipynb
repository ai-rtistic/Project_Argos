{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdHTuY28zBBK",
    "outputId": "269353bd-11aa-422f-8900-c2980bb216cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lG7BJMX9bGE",
    "outputId": "4db6c674-ae76-4ab3-bdb5-644435931631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/아르고스/ResNet\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/아르고스/ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0yzFS38-zQLG"
   },
   "outputs": [],
   "source": [
    "!unzip -qq \"/content/drive/MyDrive/아르고스/ResNet/restnet_dataset.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2ZFevbP9wTn"
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iB_5kSEJ9vAr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9n_NWk2H9zUZ",
    "outputId": "8724433c-b7cf-4839-a659-f0a6555f4d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnvreZa_94ie"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dSG3ohC9X0Ja"
   },
   "outputs": [],
   "source": [
    "#배치 사이즈 및, 에폭 설정\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04frCOVkX2jH",
    "outputId": "b76f4862-dc2a-4d27-bf45-974e80cdcc82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "#데이터를 dataloader에 담아주는 과정\n",
    "transform_base = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()]) \n",
    "\n",
    "train_dataset = ImageFolder(root='/content/drive/MyDrive/아르고스/ResNet/market1501/train', transform=transform_base) \n",
    "val_dataset = ImageFolder(root='/content/drive/MyDrive/아르고스/ResNet/market1501/val', transform=transform_base)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kO5ubR6AyU3"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgeB1Yy6y7iF",
    "outputId": "73b06a43-ee05-4c9b-b4c7-74068c89b388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       BottleNeck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 2]           4,098\n",
      "================================================================\n",
      "Total params: 23,512,130\n",
      "Trainable params: 23,512,130\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.69\n",
      "Estimated Total Size (MB): 376.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4 #블록의 마지막 레이어에서 출력 차원을 4배로 늘린다\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #Resnet50은 1x1, 3x3, 1x1을 거치는 3개의 컨볼루션 레이어가 하나의 블록으로 구성된다.\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential() #x를 그대로 사용\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        #stride가 2 이상이어서 feature map의 크기가 다르거나, 출력층의 채널수가 다른 경우 1x1컨볼루션을 이용해 x의 크기를 맞춰준다.\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=2, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        #7x7의 컨볼루션 레이어와 맥스풀링\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        #3개의 블록이 있으며 3x3 컨볼루션 레이어에서도 stride를 1로 두어 output size에 변화가 없다.\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        #conv3~5에서는 각각 4,6,3개의 블록이 있으며 3x3 컨볼루션 레이어에서 stride를 2로 두어 output size가 절반으로 줄어든다.\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        #Average Pooling을 통해 각 채널에서의 평균값 추출\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        #마지막 출력층의 채널 수인 512*4개가 input으로 들어가 클래수의 수만큼 출력한다.\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        #가중치 초기화\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "# print model summary\n",
    "model_base = resnet50().to(DEVICE)\n",
    "summary(model_base, (3, 224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlp7_e-7UjjS",
    "outputId": "a0471bba-ebac-4731-c858-1afde4b4400d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n"
     ]
    }
   ],
   "source": [
    "#출력 사이즈 확인\n",
    "x = torch.randn(50, 3, 224, 224).to(DEVICE)\n",
    "output = model_base(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rslSSCoAA5Ug"
   },
   "outputs": [],
   "source": [
    "# Optimizer, Loss function\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "th-2zcPLA5WO"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()  # 모델 train 상태로\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)   # data, target 값 DEVICE에 할당\n",
    "        optimizer.zero_grad()                               # optimizer gradient 값 초기화\n",
    "        output = model(data)                                # 할당된 데이터로 output 계산\n",
    "        loss = criterion(output, target)                    # Cross Entropy Loss 사용해 loss 계산\n",
    "        loss.backward()                                     # 계산된 loss back propagation\n",
    "        optimizer.step()                                    # parameter update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UebmmqfmA5YL"
   },
   "outputs": [],
   "source": [
    "#evaluate\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()      # 모델 평가 상태로\n",
    "    test_loss = 0     # test_loss 초기화\n",
    "    correct = 0       # 맞게 예측한 개수. 0 값으로 초기화\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)     # data, target DEVICE에 할당\n",
    "            output = model(data)                                  # output 계산\n",
    "            test_loss += criterion(output, target).item()         # loss 계산(총 loss 에 더해주기)\n",
    "            pred = output.max(1, keepdim=True)[1]                 # 계산된 벡터값 중 가장 큰 값 가지는 class 예측\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # 맞게 예측한 값 세기\n",
    "   \n",
    "    test_loss /= len(test_loader.dataset)                         # 평균 loss\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)     # test(validation) 데이터 정확도\n",
    "    return test_loss, test_accuracy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo6NZqLmBGQl"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAqivTJNBHOC",
    "outputId": "89b7f1a5-8181-417b-8d17-6c7be37fb2b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train Loss: 0.0229, Accuracy: 48.88%\n",
      "val Loss: 0.0348, Accuracy: 50.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 2 ----------------\n",
      "train Loss: 0.0168, Accuracy: 52.77%\n",
      "val Loss: 0.0272, Accuracy: 52.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 3 ----------------\n",
      "train Loss: 0.0116, Accuracy: 63.83%\n",
      "val Loss: 0.0229, Accuracy: 55.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 4 ----------------\n",
      "train Loss: 0.0182, Accuracy: 59.76%\n",
      "val Loss: 0.0327, Accuracy: 57.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 5 ----------------\n",
      "train Loss: 0.0063, Accuracy: 80.85%\n",
      "val Loss: 0.0122, Accuracy: 72.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 6 ----------------\n",
      "train Loss: 0.0113, Accuracy: 67.54%\n",
      "val Loss: 0.0204, Accuracy: 65.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 7 ----------------\n",
      "train Loss: 0.0141, Accuracy: 70.58%\n",
      "val Loss: 0.0255, Accuracy: 75.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 8 ----------------\n",
      "train Loss: 0.0088, Accuracy: 76.66%\n",
      "val Loss: 0.0180, Accuracy: 67.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 9 ----------------\n",
      "train Loss: 0.0067, Accuracy: 80.49%\n",
      "val Loss: 0.0133, Accuracy: 72.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 10 ----------------\n",
      "train Loss: 0.0076, Accuracy: 82.55%\n",
      "val Loss: 0.0120, Accuracy: 85.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 11 ----------------\n",
      "train Loss: 0.0114, Accuracy: 78.66%\n",
      "val Loss: 0.0300, Accuracy: 70.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 12 ----------------\n",
      "train Loss: 0.0075, Accuracy: 78.42%\n",
      "val Loss: 0.0165, Accuracy: 75.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 13 ----------------\n",
      "train Loss: 0.0073, Accuracy: 81.82%\n",
      "val Loss: 0.0170, Accuracy: 75.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 14 ----------------\n",
      "train Loss: 0.0036, Accuracy: 91.37%\n",
      "val Loss: 0.0137, Accuracy: 80.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 15 ----------------\n",
      "train Loss: 0.0026, Accuracy: 93.80%\n",
      "val Loss: 0.0072, Accuracy: 90.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 16 ----------------\n",
      "train Loss: 0.0034, Accuracy: 92.16%\n",
      "val Loss: 0.0099, Accuracy: 85.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 17 ----------------\n",
      "train Loss: 0.0062, Accuracy: 86.20%\n",
      "val Loss: 0.0195, Accuracy: 77.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 18 ----------------\n",
      "train Loss: 0.0013, Accuracy: 97.39%\n",
      "val Loss: 0.0103, Accuracy: 82.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 19 ----------------\n",
      "train Loss: 0.0083, Accuracy: 91.55%\n",
      "val Loss: 0.0181, Accuracy: 82.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 20 ----------------\n",
      "train Loss: 0.0007, Accuracy: 98.60%\n",
      "val Loss: 0.0071, Accuracy: 90.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 21 ----------------\n",
      "train Loss: 0.0182, Accuracy: 74.95%\n",
      "val Loss: 0.0605, Accuracy: 60.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 22 ----------------\n",
      "train Loss: 0.0008, Accuracy: 98.12%\n",
      "val Loss: 0.0051, Accuracy: 90.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 23 ----------------\n",
      "train Loss: 0.0026, Accuracy: 95.08%\n",
      "val Loss: 0.0139, Accuracy: 82.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 24 ----------------\n",
      "train Loss: 0.0125, Accuracy: 73.01%\n",
      "val Loss: 0.0447, Accuracy: 62.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 25 ----------------\n",
      "train Loss: 0.0006, Accuracy: 98.66%\n",
      "val Loss: 0.0103, Accuracy: 85.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 26 ----------------\n",
      "train Loss: 0.0018, Accuracy: 96.23%\n",
      "val Loss: 0.0017, Accuracy: 97.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 27 ----------------\n",
      "train Loss: 0.0040, Accuracy: 93.01%\n",
      "val Loss: 0.0195, Accuracy: 85.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 28 ----------------\n",
      "train Loss: 0.0015, Accuracy: 96.47%\n",
      "val Loss: 0.0107, Accuracy: 87.50%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 29 ----------------\n",
      "train Loss: 0.0183, Accuracy: 77.69%\n",
      "val Loss: 0.0416, Accuracy: 70.00%\n",
      "Completed in 0m 14s\n",
      "-------------- epoch 30 ----------------\n",
      "train Loss: 0.0026, Accuracy: 93.80%\n",
      "val Loss: 0.0144, Accuracy: 80.00%\n",
      "Completed in 0m 14s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    " \n",
    "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
    "    best_acc = 0.0  # best accuracy 초기화\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    " \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()                                     # 학습 시간 계산\n",
    "        train(model, train_loader, optimizer)                   # train 데이터로 학습\n",
    "        train_loss, train_acc = evaluate(model, train_loader)   # train_loss, train_acc 계산\n",
    "        val_loss, val_acc = evaluate(model, val_loader)         # valid_loss, valid_acc 계산\n",
    "        \n",
    "        if val_acc>best_acc:  # update best accuracy\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since # 학습 시간 출력\n",
    "        print('-------------- epoch {} ----------------'.format(epoch))\n",
    "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
    "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
    "\n",
    "    model.load_state_dict(best_model_wts)  \n",
    "    return model\n",
    "\n",
    "base = train_baseline(model_base ,train_loader, val_loader, optimizer)  \t# 모델 학습시키기\n",
    "torch.save(base,'/content/drive/MyDrive/아르고스/ResNet/resnet.pt')      # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uqz-hy30BLuT",
    "outputId": "afbd5cde-3079-40e9-c595-fc8bf95cac4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "transform_base = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()]) \n",
    "test_base = ImageFolder(root='/content/drive/MyDrive/아르고스/ResNet/market1501/test',transform=transform_base)  \n",
    "test_loader_base = torch.utils.data.DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8fTkqzKdpn8z"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval() #eval 모드\n",
    "    result = None #모델을 거친 확률값(7개 클래스에 대한 softmax)\n",
    "    targets = None #실제 target\n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:  \n",
    "            data = data.to(DEVICE)\n",
    "            #비어있을 경우 그대로 넣어주고\n",
    "            if result is None:\n",
    "              result = model(data).cpu().numpy()\n",
    "              targets = target.cpu().numpy()\n",
    "            #이미 값이 있을 경우 concat을 통해 추가해준다\n",
    "            else:\n",
    "              result = np.concatenate((result, model(data).cpu().numpy()))\n",
    "              targets = np.concatenate((targets, target))\n",
    "    return result, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfaqGgQb1ZuI"
   },
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxZiw7hytuZe",
    "outputId": "2a1c7cfe-e348-4bdd-ffd9-7b2f4f5c5e43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "y_pred_base, y_true_base = predict(base, test_loader_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fskesmCAz32A",
    "outputId": "97a27d94-363e-4ba1-cb82-703997089b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base모델 정확도: 0.875\n",
      "base모델 오차 행렬:\n",
      " [[17  2]\n",
      " [ 3 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "print(\"base모델 정확도: {:.3f}\".format(accuracy_score(y_pred_base.argmax(axis=1), y_true_base))) #y_pred_base는 확률값이므로 argmax를 통해 예측 클래스를 뽑는다\n",
    "print(\"base모델 오차 행렬:\\n\", confusion_matrix(y_pred_base.argmax(axis=1), y_true_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoxCF2940l9o",
    "outputId": "35606e45-bf24-4431-d841-e8c00dba42eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        19\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.88      0.88      0.87        40\n",
      "weighted avg       0.88      0.88      0.88        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_pred_base.argmax(axis=1), y_true_base))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_AIFFEL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
